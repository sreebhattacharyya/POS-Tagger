{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS Tagger.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jDMOq0GDd5aP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declaring a few util functions\n",
        "import string\n",
        "\n",
        "punct = set(string.punctuation)\n",
        "\n",
        "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
        "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
        "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
        "adv_suffix = [\"ward\", \"wards\", \"wise\"]\n",
        "\n",
        "def get_word_tag(line, vocab):\n",
        "  \"\"\"\n",
        "  function to get the correct tag for a word\n",
        "  \"\"\"\n",
        "  if not line.split():\n",
        "    word = \"--n--\"\n",
        "    tag = \"--s--\"\n",
        "    return word, tag\n",
        "  else:\n",
        "    word, tag = line.split()\n",
        "    if word not in vocab: \n",
        "      # Handle unknown words\n",
        "      word = assign_unk(word)\n",
        "    return word, tag\n",
        "  return None \n",
        "\n",
        "\n",
        "def preprocess(vocab, data_fp):\n",
        "  \"\"\"\n",
        "  Preprocess data\n",
        "  \"\"\"\n",
        "  orig = []\n",
        "  prep = []\n",
        "\n",
        "  with open(data_fp, \"r\") as infile:\n",
        "    for i, word in enumerate(infile):\n",
        "      if not word.split():\n",
        "        orig.append(word.strip())\n",
        "        word = \"--n--\"\n",
        "        prep.append(word)\n",
        "        continue\n",
        "      elif word.strip() not in vocab:\n",
        "        orig.append(word.strip())\n",
        "        word = assign_unk(word)\n",
        "        prep.append(word)\n",
        "        continue\n",
        "      else:\n",
        "        orig.append(word.strip())\n",
        "        prep.append(word.strip())\n",
        "    \n",
        "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
        "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
        "\n",
        "    return orig, prep\n",
        "\n",
        "def assign_unk(tok):\n",
        "  \"\"\"\n",
        "  Assign unknown word tokens\n",
        "  \"\"\"\n",
        "  # Digits\n",
        "  if any(char.isdigit() for char in tok):\n",
        "    return \"--unk_digit--\"\n",
        "\n",
        "  # Punctuation\n",
        "  elif any(char in punct for char in tok):\n",
        "    return \"--unk_punct--\"\n",
        "\n",
        "  # Upper-case\n",
        "  elif any(char.isupper() for char in tok):\n",
        "    return \"--unk_upper--\"\n",
        "\n",
        "  # Nouns\n",
        "  elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
        "    return \"--unk_noun--\"\n",
        "\n",
        "  # Verbs\n",
        "  elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
        "    return \"--unk_verb--\"\n",
        "\n",
        "  # Adjectives\n",
        "  elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
        "    return \"--unk_adj--\"\n",
        "\n",
        "  # Adverbs\n",
        "  elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
        "    return \"--unk_adv--\"\n",
        "\n",
        "  return \"--unk--\""
      ],
      "metadata": {
        "id": "4QEr2VFFYbAS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the training corpus\n",
        "with open(\"WSJ_02-21.pos\", \"r\") as infile:\n",
        "  training = infile.readlines()\n",
        "\n",
        "print(training[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvXCWcCpbdDQ",
        "outputId": "37208835-b4e1-4404-b144-7b46422f830c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the vocab\n",
        "with open(\"hmm_vocab.txt\", 'r') as voc_infile:\n",
        "  # reading lines of the vocab\n",
        "  voc_lines = voc_infile.read().split(\"\\n\")\n",
        "print(voc_lines[:5])\n",
        "print(len(voc_lines))\n",
        "\n",
        "#i = 0\n",
        "#for k, v in vocab.items():\n",
        "#  print(f'{k}:{v}')\n",
        "#  i += 1\n",
        " # if i > 20:\n",
        "  #  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKGL7W5xHyoO",
        "outputId": "2d09fee5-3cd1-40f9-aeb9-6d0b4af95bd2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['!', '#', '$', '%', '&']\n",
            "23777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "voc_lines[-5:]"
      ],
      "metadata": {
        "id": "OCdRFO-1IpqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2fbec3-0837-4017-e48f-2caa2f5b1e8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zones', 'zoning', '{', '}', '']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary with the index of the words in the vocab\n",
        "vocab = {}\n",
        "for i, word in enumerate(sorted(voc_lines)):\n",
        "  vocab[word] = i\n",
        "\n",
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1r7oZWoKQxv",
        "outputId": "feb12446-be2e-496a-fccd-61da7ddd08a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23777"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the test corpus\n",
        "with open(\"WSJ_24.pos\", 'r') as test_infile:\n",
        "  y = test_infile.readlines()\n",
        "\n",
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv-3vejLN3DS",
        "outputId": "4c33c0ac-dea2-445d-89df-7df3cc48eb22"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The\\tDT\\n',\n",
              " 'economy\\tNN\\n',\n",
              " \"'s\\tPOS\\n\",\n",
              " 'temperature\\tNN\\n',\n",
              " 'will\\tMD\\n',\n",
              " 'be\\tVB\\n',\n",
              " 'taken\\tVBN\\n',\n",
              " 'from\\tIN\\n',\n",
              " 'several\\tJJ\\n',\n",
              " 'vantage\\tNN\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, prep = preprocess(vocab, \"test.words\")\n",
        "\n",
        "print(f'Length of preprocessed test corpus = {len(prep)}')\n",
        "prep[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsSNVkOmPueK",
        "outputId": "a8fc5580-63a6-4cab-be70-7f433fa33b43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of preprocessed test corpus = 34199\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'economy',\n",
              " \"'s\",\n",
              " 'temperature',\n",
              " 'will',\n",
              " 'be',\n",
              " 'taken',\n",
              " 'from',\n",
              " 'several',\n",
              " '--unk--']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the transition, emission and tag counts\n",
        "def create_dictionaries(training_corpus, vocab):\n",
        "  \"\"\"\n",
        "  Input: \n",
        "    training_corpus: a corpus where each line has a word followed by a tag\n",
        "    vocab: a dictionary were keys are words and values are their frequencies\n",
        "  Output:\n",
        "    transition_counts: dictionary where keys are pairs of type (previous_tag, tag) and values are their counts\n",
        "    emission_counts: dictionary where keys are pairs of type (tag, word) and values are their frequencies\n",
        "    tag_counts: dictionary where keys are tags and values are their corresponding frequencies in the training corpus\n",
        "  \"\"\"\n",
        "\n",
        "  # init dictionaries\n",
        "  emission_counts = defaultdict(int)\n",
        "  transition_counts = defaultdict(int)\n",
        "  tag_counts = defaultdict(int)\n",
        "\n",
        "  # init prev_tag with starting placeholder\n",
        "  prev_tag = \"--s--\"\n",
        "\n",
        "  i = 0 # counter to track the line number in training corpus\n",
        "\n",
        "  # looping through all items in training corpus\n",
        "  for word_tag in training_corpus: \n",
        "    i+=1\n",
        "    #print(word_tag)\n",
        "    # obtaining the word and tag\n",
        "    word, tag = get_word_tag(word_tag, vocab)\n",
        "\n",
        "    # updating transition_counts dict\n",
        "    transition_counts[(prev_tag, tag)] += 1\n",
        "\n",
        "    # updating emission_counts dict\n",
        "    emission_counts[(tag, word)] += 1\n",
        "\n",
        "    # updating tag_count\n",
        "    tag_counts[tag] += 1\n",
        "\n",
        "    prev_tag = tag\n",
        "  \n",
        "  return transition_counts, emission_counts, tag_counts\n"
      ],
      "metadata": {
        "id": "D1RDa9pGP9Nv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transition_counts, emission_counts, tag_counts = create_dictionaries(training, vocab)"
      ],
      "metadata": {
        "id": "924oUX_QxQBV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(transition_counts))\n",
        "print(len(emission_counts))\n",
        "print(len(tag_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBAk51AGxgXU",
        "outputId": "d6bb0441-d8b2-4c6a-9a8d-19e841f61421"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1421\n",
            "31140\n",
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A complete description of the tag set can be found [here](https://www.clips.uantwerpen.be/pages/mbsp-tags)."
      ],
      "metadata": {
        "id": "CPdZfpU5zXjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states = sorted(tag_counts.keys())\n",
        "print(len(hidden_states))\n",
        "print(hidden_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvTWa4_Uywpu",
        "outputId": "0ea7a243-2dbe-4459-807f-873135b0d6d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking examples of transitions, emissions and ambiguous words\n",
        "print(\"A few transition examples:\")\n",
        "for ex in list(transition_counts.items())[:3]:\n",
        "  print(ex)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"A few emission exampels:\")\n",
        "for ex in list(emission_counts.items())[:5]:\n",
        "  print(ex)\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Examples of ambiguous words (words with more than one tag):\")\n",
        "for pair, cnt in emission_counts.items():\n",
        "  if pair[1] == 'back' or pair[1] == 'well':\n",
        "    print(pair, cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jXKnxIRy8rf",
        "outputId": "33a7ee83-1080-4113-a2d7-1d0daf13b89b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A few transition examples:\n",
            "(('--s--', 'IN'), 5050)\n",
            "(('IN', 'DT'), 32364)\n",
            "(('DT', 'NNP'), 9044)\n",
            "\n",
            "A few emission exampels:\n",
            "(('IN', 'In'), 1735)\n",
            "(('DT', 'an'), 3142)\n",
            "(('NNP', 'Oct.'), 317)\n",
            "(('CD', '19'), 100)\n",
            "(('NN', 'review'), 36)\n",
            "\n",
            "Examples of ambiguous words (words with more than one tag):\n",
            "('RB', 'well') 409\n",
            "('RB', 'back') 304\n",
            "('UH', 'well') 5\n",
            "('VB', 'back') 20\n",
            "('RP', 'back') 84\n",
            "('JJ', 'back') 25\n",
            "('NN', 'back') 29\n",
            "('VBP', 'back') 4\n",
            "('NN', 'well') 9\n",
            "('JJ', 'well') 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(emission_counts.items())[200:203]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI5eO0ky0hHM",
        "outputId": "e134f843-ccb5-42ae-e238-0c5294bc4a87"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('DT', 'any'), 721), (('NN', 'decrease'), 7), (('NN', 'insider-trading'), 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing using just the emission counts dictionary\n",
        "# this will assign a tag to each word in the preprocessed testing corpus - prep\n",
        "# this will also calculate the accuracy of the model using the ground truth tags in y\n",
        "\n",
        "def predict_pos(prep, y, emission_counts, vocab, states):\n",
        "  \"\"\"\n",
        "  Function to predict the POS tag for each word in the preprocessed test corpus\n",
        "  Input:\n",
        "    prep: a preprocessed version of the test corpus - a list containing all the words in the test corpus\n",
        "    y: the original test corpus, with words and corresponding ground truth tags\n",
        "    emission_counts: dictionary storing the frequency of (tag,word) occurrences\n",
        "    vocab: dict where keys are words and values are indices\n",
        "    states: sorted list of all possible tags / hidden states\n",
        "  Output:\n",
        "    accuracy: number of times the tagger predicts correctly\n",
        "  \"\"\"\n",
        "\n",
        "  crct_cnt = 0\n",
        "\n",
        "  # getting all possible unique pairs of (tag,words)\n",
        "  all_pairs = set(emission_counts.keys())\n",
        "\n",
        "  # count of tuples in the test corpus\n",
        "  total = len(y)\n",
        "  act_cnt = 0\n",
        "  for word, y_tup in zip(prep, y):\n",
        "    # splitting into a list of word and POS\n",
        "    y_tup_l = y_tup.split()\n",
        "    # checking if it contains both the word and POS\n",
        "    if len(y_tup_l) == 2:\n",
        "      true_lab = y_tup_l[1]\n",
        "    else:\n",
        "      continue\n",
        "    \n",
        "    largest_cnt = 0\n",
        "    final_pos = '' \n",
        "\n",
        "    if word in vocab:\n",
        "      act_cnt += 1\n",
        "      for pos in states:\n",
        "        key = (pos, word)\n",
        "\n",
        "        if key in emission_counts:\n",
        "          count = emission_counts[key]\n",
        "\n",
        "          if count > largest_cnt:\n",
        "            largest_cnt = count\n",
        "            final_pos = pos\n",
        "        \n",
        "      if final_pos == true_lab:\n",
        "        crct_cnt += 1\n",
        "      \n",
        "  accuracy = crct_cnt/act_cnt\n",
        "  return accuracy      \n"
      ],
      "metadata": {
        "id": "oPkoRhXP1NyA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = predict_pos(prep, y, emission_counts, vocab, hidden_states)\n",
        "print(f\"Accuracy of tagger using just emission counts = {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj6Gd_bMAgsR",
        "outputId": "886c13d7-7746-4ca6-91ae-907a61a965a7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of tagger using just emission counts = 0.9252731866191825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
        "  \"\"\"\n",
        "  Function to calculate the transition probabilities matrix\n",
        "  Input: \n",
        "    alpha: Smoothing parameter\n",
        "    tag_counts: dictionary storing the frequency of occurrence of each tag\n",
        "    transition_counts: dictionary storing (prev_tag, tag) -> occurrence count key value pairs\n",
        "  Output:\n",
        "    A: a matrix of dim (num_tags, num_tags) storing smoothed probabilities of transitions between the different tags\n",
        "  \"\"\"\n",
        "\n",
        "  all_tags = (sorted(tag_counts.keys()))\n",
        "  num_tags = len(all_tags)\n",
        "\n",
        "  # init matrix A\n",
        "  A = np.zeros((num_tags, num_tags))\n",
        "\n",
        "  # obtaining the unique transition pair keys\n",
        "  trans_keys = set(transition_counts.keys())\n",
        "\n",
        "  for i in range(num_tags):\n",
        "    for j in range(num_tags):\n",
        "      count = 0\n",
        "      key = (all_tags[i], all_tags[j])\n",
        "\n",
        "      if key in trans_keys:\n",
        "        count = transition_counts[key]\n",
        "      count_prev_tag = tag_counts[all_tags[i]]\n",
        "\n",
        "      A[i,j] = (count + alpha)/((count_prev_tag) + (alpha*num_tags))\n",
        "  return A\n",
        "\n"
      ],
      "metadata": {
        "id": "z7tnFBs1AoHy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001\n",
        "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
        "\n",
        "print(f\"A at row 0, col 0: {A[0,0]:.9f}\")\n",
        "print(f\"A at row 3, col 1: {A[3,1]:.4f}\")\n",
        "\n",
        "print(\"A subset of the transition matrix A:\")\n",
        "print()\n",
        "A_sub = pd.DataFrame(A[0:5, 30:35], index = hidden_states[0:5], columns = hidden_states[30:35])\n",
        "print(A_sub)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac3CNB5IeBwq",
        "outputId": "ffacff2f-cc1a-49ab-8876-f40d5f821b9f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A at row 0, col 0: 0.000007040\n",
            "A at row 3, col 1: 0.1691\n",
            "A subset of the transition matrix A:\n",
            "\n",
            "             RBS            RP           SYM            TO            UH\n",
            "#   7.039973e-06  7.039973e-06  7.039973e-06  7.039973e-06  7.039973e-06\n",
            "$   1.356476e-07  1.356476e-07  1.356476e-07  1.356476e-07  1.356476e-07\n",
            "''  1.445286e-07  1.445286e-07  1.445286e-07  1.604282e-02  1.445286e-07\n",
            "(   7.320398e-07  7.320398e-07  7.320398e-07  5.125010e-03  3.660931e-03\n",
            ")   7.267199e-07  7.267199e-07  7.267199e-07  2.034888e-02  7.267199e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
        "  \"\"\"\n",
        "  Function to calculate the emission probability matrix\n",
        "  Input: \n",
        "    alpha: smoothing parameter\n",
        "    tag_counts: frequency of occurrence of all the tags\n",
        "    emission_counts: frequency of occurrence of (tag, word) pairs\n",
        "    vocab: dictionary storing the index of words \n",
        "  Output:\n",
        "    B: emission probability matrix\n",
        "  \"\"\"\n",
        "\n",
        "  # get total number of tags\n",
        "  num_tags = len(tag_counts)\n",
        "\n",
        "  # getting list of all tags \n",
        "  all_tags = sorted(tag_counts.keys())\n",
        "\n",
        "  # get total number of words\n",
        "  num_words = len(vocab)\n",
        "\n",
        "  # getting all words \n",
        "  #all_words = list(vocab.keys())\n",
        "\n",
        "  # init emission probabilities matrix\n",
        "  B = np.zeros((num_tags, num_words))\n",
        "\n",
        "  # getting all the emission_counts keys\n",
        "  emiss_keys = set(list(emission_counts.keys()))\n",
        "\n",
        "  for i in range(num_tags):\n",
        "    for j in range(num_words):\n",
        "      count = 0\n",
        "      key = (all_tags[i], vocab[j])\n",
        "\n",
        "      if key in emiss_keys:\n",
        "        count = emission_counts[key]\n",
        "      \n",
        "      count_tag = tag_counts[all_tags[i]]\n",
        "\n",
        "      B[i,j] = (count + alpha)/(count_tag + (alpha*num_words))\n",
        "  \n",
        "  return B"
      ],
      "metadata": {
        "id": "3XMwYb8wyTck"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the emission probability matrix\n",
        "\n",
        "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
        "\n",
        "# verifying part of the emission matrix\n",
        "\n",
        "print(f\"B[0,0] = {B[0,0]:.9f}\")\n",
        "print(f\"B[3,1] = {B[3,1]:.9f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTI9VS6zsHKt",
        "outputId": "336b7d1a-56de-4f78-c318-aecea2ec4aa3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B[0,0] = 0.000006032\n",
            "B[3,1] = 0.000000720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viterbi Algorithm:"
      ],
      "metadata": {
        "id": "2k53yhDBwxWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the best_paths and best_probabilities matrices\n",
        "def initialize(states, tag_counts, A, B, corpus, vocab):\n",
        "  \"\"\"\n",
        "  Function to initialize the best_probs and best_path matrices\n",
        "  Input: \n",
        "    states: list of all hidden states (tags)\n",
        "    tag_counts: frequency of occurrence of all the tags\n",
        "    A: transition probability matrix\n",
        "    B: emission probability matrix\n",
        "    corpus: sequence of words whose POS is to be identified\n",
        "    vocab: dictionary of (word, index) pair\n",
        "  Output:\n",
        "    best_probs: (num_tags, len(corpus)) matrix to identify max prob of following a transition sequence\n",
        "    best_paths: (num_tags, len(corpus)) matrix of ints to store labels for all states traversed\n",
        "  \"\"\"\n",
        "\n",
        "  num_tags = len(tag_counts)\n",
        "\n",
        "  best_probs = np.zeros((num_tags, len(corpus)), dtype=float)\n",
        "  best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
        "\n",
        "  s_idx = states.index(\"--s--\")\n",
        "\n",
        "  for i in range(num_tags):\n",
        "    if A[s_idx, i] == 0:\n",
        "    # special case when transition probability from --s-- to tag is 0\n",
        "      best_probs[i,0] = float('-inf')\n",
        "    else:\n",
        "      best_probs[i, 0] = (math.log(A[s_idx, i])) + math.log(B[i,vocab[corpus[0]]])\n",
        "  \n",
        "  return best_probs, best_paths"
      ],
      "metadata": {
        "id": "IiKrp5fksxoE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_probs, best_paths = initialize(hidden_states, tag_counts, A, B, prep, vocab)"
      ],
      "metadata": {
        "id": "Hry3mShdvROQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"best_probs[0,0]:{best_probs[0,0]:.4f}\")\n",
        "print(f\"best_probs[2,3]:{best_probs[2,3]:.4f}\")\n",
        "best_probs[2,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0MQWYNQMFmw",
        "outputId": "dbaeda11-ac5b-4d76-fa72-4d4b5712613d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_probs[0,0]:-22.6098\n",
            "best_probs[2,3]:0.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-23.572988219423895"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi_forward(A, B, test_corpus, best_probs, best_paths, vocab):\n",
        "    '''\n",
        "    Input: \n",
        "        A, B: The transiton and emission matrices respectively\n",
        "        test_corpus: a list containing a preprocessed corpus\n",
        "        best_probs: an initilized matrix of dimension (num_tags, len(corpus))\n",
        "        best_paths: an initilized matrix of dimension (num_tags, len(corpus))\n",
        "        vocab: a dictionary where keys are words in vocabulary and value is an index \n",
        "    Output: \n",
        "        best_probs: a completed matrix of dimension (num_tags, len(corpus))\n",
        "        best_paths: a completed matrix of dimension (num_tags, len(corpus))\n",
        "    '''\n",
        "    num_tags = best_probs.shape[0]\n",
        "    \n",
        "    for i in range(1, len(test_corpus)): \n",
        "        \n",
        "        if i % 5000 == 0:\n",
        "            print(\"Words processed: {:>8}\".format(i))\n",
        "            \n",
        "        for j in range(num_tags): \n",
        "            \n",
        "            # Initialize best_prob for word i to negative infinity\n",
        "            best_prob_i = float(\"-inf\")\n",
        "            \n",
        "            # Initialize best_path for current word i to None\n",
        "            best_path_i = None\n",
        "\n",
        "            \n",
        "            for k in range(num_tags): \n",
        "            \n",
        "                prob = best_probs[k,i-1]+math.log(A[k,j]) +math.log(B[j,vocab[test_corpus[i]]])\n",
        "\n",
        "                if prob > best_prob_i: \n",
        "                    \n",
        "                    # Keep track of the best probability\n",
        "                    best_prob_i = prob\n",
        "                    \n",
        "                    # keep track of the POS tag of the previous word\n",
        "                    best_path_i = k\n",
        "\n",
        "            \n",
        "            best_probs[j,i] = best_prob_i\n",
        "            best_paths[j,i] = best_path_i\n",
        "\n",
        "    return best_probs, best_paths"
      ],
      "metadata": {
        "id": "tcLbp2RcMN4W"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_probs, best_paths = viterbi_forward(A, B, prep, best_probs, best_paths, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Klc_6q2hRhXT",
        "outputId": "0c2edc8b-4b4d-4408-d5a8-d7edc894d031"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words processed:     5000\n",
            "Words processed:    10000\n",
            "Words processed:    15000\n",
            "Words processed:    20000\n",
            "Words processed:    25000\n",
            "Words processed:    30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"best_probs[0,1] = {best_probs[0,1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYVZDaqHRn7C",
        "outputId": "c60d7b03-b733-426e-c54a-75e2212975fa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_probs[0,1] = -24.7822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_probs[0,4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UVCGxQdRvBW",
        "outputId": "a225e29d-9015-4afb-8daa-eb5984a39e76"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-49.560126133711904"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# viterbi backward pass\n",
        "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
        "  \"\"\"\n",
        "  Function to assign tags by backtracking using matrices populated in the forward pass\n",
        "  Output: \n",
        "    z: An array having same size as test_corpus storing corresponding states\n",
        "  \"\"\"\n",
        "  # obtain size of corpus\n",
        "  m = best_probs.shape[1]\n",
        "\n",
        "  # obtaining number of tags\n",
        "  num_tags = best_probs.shape[0]\n",
        "\n",
        "  # initialize result array\n",
        "  z = [None] * m\n",
        "  pred = [None] * m\n",
        "\n",
        "  # find max probability tag for last word\n",
        "  best_lw_prob = float('-inf')\n",
        "  for k in range(num_tags):\n",
        "    if best_probs[k,m-1] > best_lw_prob:\n",
        "      best_lw_prob = best_probs[k,m-1]\n",
        "      z[m-1] = k\n",
        "  \n",
        "  pred[m-1] = states[z[m-1]]\n",
        "\n",
        "  # finding POS tags for previous words by backtracking\n",
        "\n",
        "  for i in range(m-1, 1, -1):\n",
        "    pos_tag_i = z[i]\n",
        "\n",
        "    z[i-1] = best_paths[pos_tag_i, i]\n",
        "\n",
        "    pred[i-1] = states[z[i-1]]\n",
        "  \n",
        "  return pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "33i88YJ6R_BA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = viterbi_backward(best_probs, best_paths, prep, hidden_states)\n",
        "\n",
        "m = len(pred)\n",
        "print('The prediction for pred[-7:m-1] is: \\n', prep[-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
        "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", prep[0:7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ix5PL2wXg-d",
        "outputId": "27c37243-6fd3-4bff-afe9-a7e4afb12940"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prediction for pred[-7:m-1] is: \n",
            " ['see', 'them', 'here', 'with', 'us', '.'] \n",
            " ['VB', 'PRP', 'RB', 'IN', 'PRP', '.'] \n",
            "\n",
            "The prediction for pred[0:8] is: \n",
            " [None, 'NN', 'POS', 'NN', 'MD', 'VB', 'VBN'] \n",
            " ['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting on preprocessed test corpus\n",
        "\n",
        "print(prep[2])\n",
        "print(pred[2])\n",
        "print(y[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs8Ixs5WXmOk",
        "outputId": "950888ce-d782-43e1-8bca-0512a95b210f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'s\n",
            "POS\n",
            "'s\tPOS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(pred, y):\n",
        "  \"\"\"\n",
        "  Function to compute accuracy of tags assigned using Viterbi algo\n",
        "  Input:\n",
        "    pred: predicted POS tags\n",
        "    y: list of lines containing the words and corresponding ground truth POS tags\n",
        "  Output:\n",
        "    accuracy score\n",
        "  \"\"\"\n",
        "\n",
        "  num_correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for prediction, word_tag in zip(pred, y):\n",
        "    wt_tuple = word_tag.split()\n",
        "\n",
        "    if len(wt_tuple) < 2:\n",
        "      continue\n",
        "    \n",
        "    word, tag = wt_tuple[0], wt_tuple[1]\n",
        "    if prediction == tag:\n",
        "      num_correct+=1\n",
        "    total+=1\n",
        "\n",
        "  return num_correct/total\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SgqGf_C_lwG-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final accuracy using the Viterbi Algorithm = {get_accuracy(pred, y):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTHbOS4_m5W9",
        "outputId": "4273297a-76f9-484f-c757-f3317770def8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final accuracy using the Viterbi Algorithm = 0.95303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HdTIwYhwnCJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}